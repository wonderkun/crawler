> 原文链接: https://www.anquanke.com//post/id/195323 


# 深度残差网络隐写分析模型探究


                                阅读量   
                                **1544998**
                            
                        |
                        
                                                            评论
                                <b>
                                    <a target="_blank">1</a>
                                </b>
                                                                                                                                    ![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsQAAA7EAZUrDhsAAAANSURBVBhXYzh8+PB/AAffA0nNPuCLAAAAAElFTkSuQmCC)
                                                                                            



##### 译文声明

本文是翻译文章，文章原作者ieee，文章来源：ieeexplore.ieee.org
                                <br>原文地址：[https://ieeexplore.ieee.org/document/8470101](https://ieeexplore.ieee.org/document/8470101)

译文仅供参考，具体内容表达以及含义原文为准

[![](https://p1.ssl.qhimg.com/t016090b426198105f4.jpg)](https://p1.ssl.qhimg.com/t016090b426198105f4.jpg)



## 前言

本文提出了一个深度残差网络隐写分析模型SRNet，它巧妙地将残差网络应用于特征提取的过程中，从而有效防止了梯度消失，并取得了很好的隐写检测效果。



## SRNet

SRNet中R代表“Residual”，它既指隐写分析中的残差特征，也指深度学习中应用快捷连接方式的残差连接层。首先描述SRNet的网络结构，再分别讲解每个组件。

### <a class="reference-link" name="%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"></a>网络结构

[![](https://p4.ssl.qhimg.com/t016ecacd807c62e0ca.png)](https://p4.ssl.qhimg.com/t016ecacd807c62e0ca.png)

上图是SRNet的体系结构。第一到第七层的主要功能是从图像中提取隐写噪声的残差信息，第8到第12层负责降低特征图的维数，最后一层是一个带有softmax激活函数的标准全连接层。

总的来说，卷积层皆使用3×3的卷积核，所使用的非线性激活函数都是ReLU。在第1-7层中都没有加入池化的处理，在第8-11层使用了大小为3×3、步长为2的平均池化操作。在第12层中，将512个大小为16×16的特征图缩减为512维特征向量。随后将这512维特征向量作为全连接层的输入进行隐写特征的分类处理。

SRNet包含两种类型的残差连接层，分别为第3-7层的残差连接层Layer type 2、第8-11层的残差连接层Layer type 3。如下图。

[![](https://p4.ssl.qhimg.com/t011c7688a749e4cd58.png)](https://p4.ssl.qhimg.com/t011c7688a749e4cd58.png)

第1、2层的网络层Layer type 1如下图所示，卷积核大小为3×3而不是5×5，因为通过实验观察发现3×3的卷积核具有更好的性能。前两层的目的是将特征图从64维缩减为16维，以节省内存。

[![](https://p4.ssl.qhimg.com/t01ae05346c0b1bb170.png)](https://p4.ssl.qhimg.com/t01ae05346c0b1bb170.png)

第4层的网络层Layer type 4如下图所示，和Layer type3相比，它的特点是应用了全局平均池化的方式处理特征图。

[![](https://p1.ssl.qhimg.com/t0140ee3791bdee9e72.png)](https://p1.ssl.qhimg.com/t0140ee3791bdee9e72.png)

### <a class="reference-link" name="%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3"></a>网络结构组件详解

SRNet的关键部分是由第一到第七层组成的隐写噪声残差提取部分。平均池化可被看作一个低通滤波器，它通过弱化相邻像素的嵌入变化程度来增强内容并抑制隐写噪声，这在典型的计算机视觉领域中有利于根据图像内容进行分类，但不利于隐写分析。在隐写分析中，根据隐写噪声进行分类，此时图像内容属于干扰因素。因此，SRNet直到第8层才开始使用平均池化操作，从而避免降低隐写噪声能量情况的发生。

下面详细讲解各组件。

（1）激活函数。除了ReLU，本文还尝试使用了TanH、ELU和SELU等激活函数，但是它们并没有带来性能的提升。简单起见，网络中的所有激活函数均确定为ReLU。注意，Layer type 2和Layer type 3中在快捷连接方式后不使用ReLU激活函数，经实验验证，这样做具有更好的隐写性能。

（2）残差快捷连接方式。为了评估SRNet中快捷方式连接的重要性，本文从Layer type 2和Layer type 3的层中删除了它们，并观察了检测精度的变化。例如，对于0.1和0.2 bpp的HILL，分类准确度的损失约为0.5％;对于0.4 bpnzac，品质因数为95的J-UNIWARD，分类准确度的损失约为1.5％。可见残差快捷连接方式能促进梯度传播，提升隐写性能。

（3）未加入池化操作的网络层。通过实验减少未加入池化操作网络层的数量，同时保持架构的其余部分不变，可发现模型的隐写检测准确率逐渐下降。通过多次实验确定在第一到第七个网络层中取消池化操作，模型具有最好的隐写检测性能。

（4）卷积核的数量。第一层卷积核的数量在JPEG域中比在空间域中影响更大。当在第一层中仅使用32或16而不是64个卷积核时，对于0.4 bpp的HILL的隐写检测误差可以忽略不计，但对于品质因子为75、0.1 bpnzac的J-UNIWARD，隐写检测错误率增加了1％。将卷积核的数量增加到64个以上时没有明显的性能提升。

（5）优化器。本文尝试了多种优化器，包括AdaDelta，Adam，Adamax，最终选择了Adamax，因为它使得训练过程中梯度能更快、更可靠地传播和汇聚。



## 实验与分析

### <a class="reference-link" name="%E6%95%B0%E6%8D%AE%E9%9B%86+%E5%8F%82%E6%95%B0"></a>数据集+参数

实验使用的数据集是**BOSSbase 1.01**和**BOWS2**，它们各自包含10000张灰度图像，使用Maltab的imresize函数将灰度图像大小调整为256×256以适应现有计算条件。

提取BOSSbase的4000对载体载密图像和BOWS2的10000对载体载密图像用于训练、提取BOSSbase的另外1000对载体载密图像用于验证、余下的5000对载体载密图像用于测试。

实验另外挑选了ImageNet数据集中的1281167张JPEG图像。对每张大于256×256且JPEG质量因子高于75的图像进行如下处理：解压缩图像到空间域（imread），再裁剪左上方大小为256×256的图像块，转换此图像为灰度图（rgb2gray），并使用品质因数75重新压缩灰度图像为JPEG图像。最终在无损可用的图像中，跳转250000对载体载密图像用于训练，挑选10000对载体载密图像用于验证，挑选余下的40000对载体载密图像用于测试。

使用随机梯度下降优化器Adamax；设置批量样本数为16；设置学习率为0.001；使用He初始器和L2正则化方法初始化卷积核。

### <a class="reference-link" name="%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90"></a>结果分析

**空域隐写分析**

对于空间域，本文测试了在WOW、HILL和S-UNIWARD为0.1-0.5 bpp的隐写分析结果，如下表所示。其中表格数据表示隐写检测错误率，分析可知除了WOW的0.1 bpp之外，SRNet均具有最低的隐写检测错误率。在WOW为0.1时，本文认为SRNet没有明确使用选择通道，而SCA-YeNet通过为WOW使用选择通道而增强了隐写检测性能。

[![](https://p5.ssl.qhimg.com/t017393dc507d6dc16d.png)](https://p5.ssl.qhimg.com/t017393dc507d6dc16d.png)

**JPEG域隐写分析**

对于JPEG域，本文测试了在J-UNIWARD和UED-JC为0.1-0.5 bpnzac、质量因子为75和95的隐写分析结果，如下表所示。可知SRNet的隐写检测错误率远远低于现有网络模型，具有绝对的隐写分析的优势。

[![](https://p3.ssl.qhimg.com/t01fea8eec0c1685eda.png)](https://p3.ssl.qhimg.com/t01fea8eec0c1685eda.png)
