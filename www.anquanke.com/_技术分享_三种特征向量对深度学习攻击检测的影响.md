> 原文链接: https://www.anquanke.com//post/id/86580 


# 【技术分享】三种特征向量对深度学习攻击检测的影响


                                阅读量   
                                **190919**
                            
                        |
                        
                                                                                    



[![](https://p2.ssl.qhimg.com/t01c40a881ac3bf27df.jpg)](https://p2.ssl.qhimg.com/t01c40a881ac3bf27df.jpg)

<br>

作者：manning@天眼实验室

<br>

**0x00 文章介绍**

****

深度学习与网络安全结合是未来网络安全的一个大趋势，我们今天以基于深度学习的主流算法对SQL注入行为进行检测，来抛出三种特征向量对深度学习模型检测效果的影响。

<br>

**0x01 深度学习简介**

****

深度学习（Deep Learning）是机器学习的分支，它试图使用包含复杂结构或由多重非线性变换构成的多个处理层对数据进行高层抽象的算法。深度学习是机器学习中一种基于对数据进行表征学习的方法。深度学习的好处是用非监督式或半监督式的特征学习和分层特征提取高效算法来替代手工获取特征。在我们的实验中，使用的是Python深度学习库： TensorFlow。使用的模型是：

**多层感知器**

多层感知器（Multilayer Perceptron,缩写MLP）是一种前向结构的人工神经网络，映射一组输入向量到一组输出向量。MLP可以被看作是一个有向图，由多个的节点层所组成，每一层都全连接到下一层。除了输入节点，每个节点都是一个带有非线性激活函数的神经元（或称处理单元）。[详细介绍](https://zh.wikipedia.org/wiki/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E5%99%A8)

**卷积神经网络**

卷积神经网络（Convolutional Neural Network, CNN）是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。卷积神经网络由一个或多个卷积层和顶端的全连通层（对应经典的神经网络）组成，同时也包括关联权重和池化层（pooling layer）。这一结构使得卷积神经网络能够利用输入数据的二维结构。与其他深度学习结构相比，卷积神经网络在图像和语音识别方面能够给出更优的结果。这一模型也可以使用反向传播算法进行训练。相比较其他深度、前馈神经网络，卷积神经网络需要估计的参数更少，使之成为一种颇具吸引力的深度学习结构。[详细介绍](https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)

**循环神经网络**

递归神经网络（RNN）是两种人工神经网络的总称。一种是时间递归神经网络（recurrent neural network），另一种是结构递归神经网络（recursive neural network）。时间递归神经网络的神经元间连接构成有向图，而结构递归神经网络利用相似的神经网络结构递归构造更为复杂的深度网络。RNN一般指代时间递归神经网络。单纯递归神经网络因为无法处理随着递归，权重指数级爆炸或消失的问题（Vanishing gradient problem），难以捕捉长期时间关联；而结合不同的LSTM可以很好解决这个问题。[详细介绍](https://zh.wikipedia.org/wiki/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)

**实验中使用的网络结构**

**多层感知器**

神经网络结构为：

**输入层**

**隐藏层 L1**

**隐藏层 L2**

**隐藏层 L3**

**输出层**

每个隐藏层使用128个神经元，激活函数为relu。 

[![](https://p1.ssl.qhimg.com/t019c594c4208d11128.png)](https://p1.ssl.qhimg.com/t019c594c4208d11128.png)



上图为 **TensorBoard** 输出的结构图。

**实验中使用的网络结构**

**卷积神经网络**

神经网络结构为：

输入层

卷积层 

池化层 

卷积层 

池化层 

全连接层

输出层

**循环神经网络**

神经网络结构为：

输入层

向前层

向后层

输出层

[![](https://p0.ssl.qhimg.com/t016f2ad22f2c5ff793.png)](https://p0.ssl.qhimg.com/t016f2ad22f2c5ff793.png)

**PS：训练集和测试集来自于360企业安全-天眼大数据平台，模型纯度良好。**



**0x02 特征向量介绍**

****

我们的特征向量转化，使用了三种方法，也是目前应对字符串比较好的方法选择。

基于word2vec的特征向量

基于词袋的特征向量

基于fofe的特征向量

**基于word2vec的特征向量**

word2vec可以根据模型把词汇转化成一个多维的特征向量，在构建语句的特征时，我们采用暴力的向量相加的方式。

word2vec在自然语言的实验中，可以很好的表示词语见的关系。具体可以参考[维基百科语料中的词语相似度探索](http://www.52nlp.cn/tag/word2vec)

**基于词袋的特征向量**

词袋向量，我们在天眼实验室的攻击平台上，挑选了在SQL注入中最常出现的250个词汇，构建词袋模型。

词袋模型的参考 [BoW（词袋）模型详细介绍](http://blog.csdn.net/u010213393/article/details/40987945)

**基于FOFE的特征向量**

FOFE是一种简单精妙的rule-base编码方式。通俗的说就是，在one-hot的基础上利用了数值的大小表明了词的位置信息的一种编码形式。我们基于上面词袋模型的基础，加入了FOFE算法。

FOFE算法的具体论文，来自江辉老师。 

[The Fixed-Size Ordinally-Forgetting Encoding Method for Neural Network Language Models](https://www.aclweb.org/anthology/P/P15/P15-2081.pdf?spm=5176.100239.blogcont118686.20.PWd2AD&amp;file=P15-2081.pdf)





**0x03 实验结果分析**

****

我们的训练数据为50000条，测试数据为500000条。

[![](https://p3.ssl.qhimg.com/t015af26f03af6fab98.png)](https://p3.ssl.qhimg.com/t015af26f03af6fab98.png)

三种向量结果都表现了非常好的准确度。

[![](https://p5.ssl.qhimg.com/t0188d552ccce08f15e.png)](https://p5.ssl.qhimg.com/t0188d552ccce08f15e.png)

从上图可以看出，基于FOFE的特征向量和词袋特征向量的表现并没有出现特别明显的差距，位置元素的融入并没有给FOFE特征向量带来明显的检测水平的提升。word2vec的向量在真实集表现的不是很好，其中的原因是我们建立句子，使用的是向量相加的粗暴方法，并不能体现word2vec对句子的属性体现。

[![](https://p3.ssl.qhimg.com/t0132a1b9d06859c41e.png)](https://p3.ssl.qhimg.com/t0132a1b9d06859c41e.png)

从上图可以看出，基于word2vec的特征向量的判断速度明显慢于其他两种方法。基于词袋的速度比基于fofe的速度快一点，本质原因是fofe算法的引入，带来了一定的计算量，符合速度降低的预期。



**0x04 总结**

****

笔者认为，本次我们利用三种建立向量的方式和三种神经网络结构进行交叉实验，探讨三种方式的向量形式和神经网络结构之间的关系，算是抛砖引玉。本次实验最为惊讶的是 CNN 和 word2vec的组合在真实集表现的最好。基于FOFE的特征向量具有顺序的概念，但是未能在词袋模型的基础上带来更好的检测结果。

深度神经网络在安全检测方面，可以带领我们进入检测“未知的未知”的能力层次，这点也是我们必须要对此付出努力的方向。路要一步一步走，我们会在这个方向上继续前行。



**0x05 参考引用**

****

[https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0](https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)

[https://yq.aliyun.com/articles/118686?spm=5176.100239.0.0.g2XnLx](http://https://yq.aliyun.com/articles/118686?spm=5176.100239.0.0.g2XnLx)

[http://www.52nlp.cn/tag/word2vec](http://http://www.52nlp.cn/tag/word2vec)

[http://blog.csdn.net/u010213393/article/details/40987945](http://http://blog.csdn.net/u010213393/article/details/40987945)
