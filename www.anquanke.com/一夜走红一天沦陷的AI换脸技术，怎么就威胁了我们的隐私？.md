> 原文链接: https://www.anquanke.com//post/id/185654 


# 一夜走红一天沦陷的AI换脸技术，怎么就威胁了我们的隐私？


                                阅读量   
                                **379666**
                            
                        |
                        
                                                            评论
                                <b>
                                    <a target="_blank">1</a>
                                </b>
                                                                                    



[![](https://p0.ssl.qhimg.com/t01e6889484b0d8fb9b.jpg)](https://p0.ssl.qhimg.com/t01e6889484b0d8fb9b.jpg) 事情起源于一个加班摸鱼的晚上，收到了一条视频消息，一个古装言情剧片段，but定睛一看，这男主角的脸不是发消息的肥宅小伙伴么？！ 看水印得知出自AI换脸APP 名字叫ZAO，并且这款软件已经在朋友圈刷了一波屏，毕竟是个新鲜玩意儿，一时间朋友圈熟悉的小伙伴都变成明星。 看大家玩儿的开心，但是AI换脸、肖像授权、数据采集、生物识别、手机号绑定。这几个关键词凑在一起，后背有没有感到一丝凉意？ [![](https://p3.ssl.qhimg.com/t01772739c34be7e318.png)](https://p3.ssl.qhimg.com/t01772739c34be7e318.png)[![](https://p0.ssl.qhimg.com/t01c9fdf84b388f4c59.png)](https://p0.ssl.qhimg.com/t01c9fdf84b388f4c59.png) 不过今天我们不谈舆论，聊聊技术和风险 告诉大家一个秘密…视频换脸这个技术，最初其实是应用在小电影上的。 [![](https://p0.ssl.qhimg.com/t01043c3045a1a0397c.png)](https://p0.ssl.qhimg.com/t01043c3045a1a0397c.png)

## 何为DeepFakes

今天我们抛开来单独讨论下技术和风险 当然，视频换脸虽然应场景很迷，但也不是突然冒出来的新技术黑科技。早在2017年，国外Reddit论坛 一个ID名为“DeepFakes”的小伙几首次将自己制作的AI换脸视频发布在网络上。但是很快就凉凉了。在被Reddit无情封杀后，DeepFakes同志直接开源了AI换脸项目的代码，造福全球宅男并立刻风靡全球。

代码开源后，只要你稍微懂点代码就能在几个小时内做出一部换脸视频。

人们为了纪念DeepFakes同志，就用它的ID命名了AI换脸技术，称之为“DeepFakes”。 [![](https://p5.ssl.qhimg.com/t01ea1a0eba39ea3a91.png)](https://p5.ssl.qhimg.com/t01ea1a0eba39ea3a91.png)

## 再来谈谈DeepFakes的应用场景

1、拿你的视频去和你的亲朋好友骗钱（都说眼见为实你觉得骗子成功率如何？ ）

2、拿你的视频去网贷（据实验，很多网贷APP的风控系统并不成熟，视频在手，离负债百万还有多远？）

3、拿你的视频去做任何对方想做的事让你的名声一败涂地。（想象一下自己的脸突然出现在不可描述的小电影里） 不好意思实在没想到有什么正能量的。

## 

## 

## DeepFakes 相关的网络安全问题

DeepFakes本质上是一个未发生事情的视频，但却可以以假乱真，看起来非常真实。它主要是通过人工智能算法对照片库中大量名人照片进行训练，因此可以输出与真实视频毫无差异的内容。只要AI训练足够多的头像，换什么都不是问题[![](https://p5.ssl.qhimg.com/t0174e4e3723bf9ca86.png)](https://p5.ssl.qhimg.com/t0174e4e3723bf9ca86.png)<br>
DeepFakes会引发很多问题，比如定期收集到的大量普通用户数据。 即使是在得到用户明确同意的情况下，大多数人也不知道网上有多少他们自己的照片。

劣币驱逐良币，设想下，如果我们根本无法检测到虚假视频，你还敢相信“眼见为实”吗？ 除此之外，DeepFakes还有一个被忽视的问题。在未来，DeepFakes将把网络攻击场景带入一个全新的层面，即图像，视频和音频可以通过数字方式进行深度伪造，欺骗人们和组织。

**今天的安全系统严重依赖监控视频和基于图像的生物识别安全。**

由于大多数漏洞都是基于社会工程的网络钓鱼攻击而发生的。不难想象我们很快就会看到“高保真”的网络钓鱼欺诈，即攻击者可以使用AI，社交工程和网络钓鱼，创建自动化、个性化的攻击内容。

为应对钓鱼攻击，对于个人而言，需要增强自身安全防范意识，不轻信、不点击来源不明的链接或附件。对于企业而言，也可以通过其它一些方法，比如在员工电脑中安装管理软件，实时监控员工的一举一动。此外，为防止攻击者通过以PC终端为跳板入侵服务器，企业需要在主机侧增强安全防护，可在主机层部署类似青藤云安全这类企业的安全产品。



## DeepFakes的工作原理和底层技术

“DeepFakes”背后技术来源于一种名为GAN（生成式对抗网络）的AI模型，它在2014年10月由前谷歌著名神级技术大咖Ian Goodfellow发布的一篇GAN论文而奠定了地位，GAN是当前人工智能学界一个最热门的研究方向。

当前的AI换脸，正是使用了GAN技术。 该技术是通过“生成模型”和“判别模型”两个机器学习(ML)模型之间较量进行不断优化。生成模型负责对数据集进行训练，然后创建伪造视频内容，而另一个判别模型尝试进行伪造检测。

伪造者创建赝品，直到另一个ML模型无法检测到伪造。训练数据集越大，伪造者越容易创建高质量的内容。这就是为什么前总统、好莱坞名人的视频经常出现在第一代DeepFakes中，主要是因为他们有大量公开的视频片段可以用来训练伪造者。



## “以彼之长还施彼身”的解决之道

DeepFakes解决之道需要教育、技术和立法的相互结合。当然，最为重要的就是技术。因为当DeepFakes变得非常逼真时，只有机器才能分辨真假视频。

虽然AI被认为是DeepFakes视频的罪魁祸首，但它也是目前为止应对DeepFakes视频最靠谱的技术。从检测发现到采取措施来消除DeepFakes带来的威胁，AI技术都是安全人员最好的办法。

值得庆幸的是DeepFakes视频仍然存在一些缺陷。比如眨眼，健康的成年人每2到10秒就会眨眼一次，一次眨眼需要十分之一秒。这对于正常视频而言非常正常，但是对于DeepFakes视频却非常难。

因为当DeepFakes算法对人脸图像进行训练时，它依赖于互联网上可用的照片作为训练数据。即使是经常被拍照的人，网上也很少有闭着眼睛的照片。因为人们的眼睛大部分时间是睁开的，而且摄影师通常不会选择拍摄和发布那些闭眼的照片。

如果不训练人们眨眼的图像，DeepFakes算法就不太可能创建正常眨眼的人脸。与真人相比，DeepFakes视频中的人物眨眼的频率要低得多。因此在检测DeepFakes视频时，可以使用机器学习来检查视频中的眼睛睁开和闭上频率。

例如，扫描视频的每一帧，检测其中的人脸，然后自动定位眼睛。然后，它利用另一个深度神经网络，利用眼睛的外观、几何特征和运动来判断被检测到的眼睛是开着还是闭着。这是检测虚假视频一个思路和手段。

当然，生成和检测假视频的竞争就像下棋一样。从理论上讲，GAN可以接受训练，学会如何躲避这样的取证。如果不法分子将所知道的检测技术都给GAN，它就能绕过所有这些检测。比如上文所说的，眨眼也一样可以添加到DeepFakes假视频中，包括使用闭着眼睛的人脸图像或视频序列进行训练。



## 写在最后

未来，虚假视频制作可能会做得越来越好，因此需要政府、企业及个人联合投入更多资源去研究检测DeepFakes假视频的技术。

此外，为应对DeepFakes虚假视频，还有一个比较好解决方案是更好地教育普通大众，“眼见并不为实”

说回ZAO ，在被广泛质疑之后，“ZAO”迅速修改了用户协议，删除了限制用户权利、强制用户无限授权的内容并做出了声明。 [![](https://n.sinaimg.cn/translate/679/w1080h2799/20190903/60ee-ieaiqii5898029.jpg)](https://n.sinaimg.cn/translate/679/w1080h2799/20190903/60ee-ieaiqii5898029.jpg)**技术无罪，无论事情最后发展如何，希望安全环境越来越好，对此，你怎么看？**
